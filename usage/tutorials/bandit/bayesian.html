

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Bayesian &mdash; GenRL 0.1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../../_static/genrl_cropped.png"/>
  
  
  

  
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Gradients" href="gradients.html" />
    <link rel="prev" title="Thompson Sampling" href="thompson_sampling.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >
          

          
            <a href="../../../index.html">
          

          
            
            <img src="../../../_static/genrl.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../about/about.html">About</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Tutorials</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Bandit Tutorials</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="bandit_overview.html">Multi Armed Bandit Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="contextual_overview.html">Contextual Bandits Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="ucb.html">UCB</a></li>
<li class="toctree-l3"><a class="reference internal" href="thompson_sampling.html">Thompson Sampling</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Bayesian</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#using-bayesian-method-on-a-bernoulli-multi-armed-bandit">Using Bayesian Method on a Bernoulli Multi-Armed Bandit</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="gradients.html">Gradients</a></li>
<li class="toctree-l3"><a class="reference internal" href="linpos.html">Linear Posterior Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="variational.html">Variational Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="bootstrap.html">Bootstrap</a></li>
<li class="toctree-l3"><a class="reference internal" href="noise.html">Parameter Noise Sampling</a></li>
<li class="toctree-l3"><a class="reference internal" href="adding_data_bandit.html">Adding a new Data Bandit</a></li>
<li class="toctree-l3"><a class="reference internal" href="adding_dcb_agent.html">Adding a new Deep Contextual Bandit Agent</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../Classical/index.html">Classical</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Deep/index.html">Deep RL Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Using%20Custom%20Policies.html">Custom Policy Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Using%20A2C.html">Using A2C</a></li>
<li class="toctree-l2"><a class="reference internal" href="../using_vpg.html">Vanilla Policy Gradient (VPG)</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/agents/index.html">Agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/environments/index.html">Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/core/index.html">Core</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/utils/index.html">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/trainers/index.html">Trainers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/common/index.html">Common</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">GenRL</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Tutorials</a> &raquo;</li>
        
          <li><a href="index.html">Bandit Tutorials</a> &raquo;</li>
        
      <li>Bayesian</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../_sources/usage/tutorials/bandit/bayesian.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="bayesian">
<h1>Bayesian<a class="headerlink" href="#bayesian" title="Permalink to this headline">¶</a></h1>
<div class="section" id="using-bayesian-method-on-a-bernoulli-multi-armed-bandit">
<h2>Using Bayesian Method on a Bernoulli Multi-Armed Bandit<a class="headerlink" href="#using-bayesian-method-on-a-bernoulli-multi-armed-bandit" title="Permalink to this headline">¶</a></h2>
<p>For an introduction to Multi Armed Bandits, refer to <a class="reference internal" href="bandit_overview.html#bandit-overview"><span class="std std-ref">Multi Armed Bandit Overview</span></a></p>
<p>This method is also based on the prinicple - ‘Optimism in the face of
uncertainty’, like
<a class="reference external" href="../../../api/bandit/genrl.agents.bandits.multiarmed.html#module-genrl.agents.bandits.multiarmed.ucb">UCB</a>.
We initially <em>assume</em> an initial distribution(prior) over the quality of
each of the arms. We can model this prior using a Beta distribution,
parametrised by alpha(<span class="math notranslate nohighlight">\(\alpha\)</span>) and beta(<span class="math notranslate nohighlight">\(\beta\)</span>).</p>
<div class="math notranslate nohighlight">
\[PDF = \frac{x^{\alpha - 1} (1-x)^{\beta -1}}{B(\alpha, \beta)}\]</div>
<p>Let’s just think of the denominator as some normalising constant, and
focus on the numerator for now. We initialise <span class="math notranslate nohighlight">\(\alpha\)</span> =
<span class="math notranslate nohighlight">\(\beta\)</span> = 1. This will result in a uniform distribution over the
values (0, 1), making all the values of quality from 0 to 1 equally
probable, so this is a fair initial assumption. Now think of
<span class="math notranslate nohighlight">\(\alpha\)</span> as the number of times we get the reward ‘1’ and
<span class="math notranslate nohighlight">\(\beta\)</span> as the number of times we get ‘0’, for a particular arm.
As our agent interacts with the environment and gets a reward for
pulling any arm, we will update our prior for that arm using Bayes
Theorem. What this does is that it gives a posterior distribution over
the quality, according to the rewards we have seen so far.</p>
<p>This is quite similar to <a class="reference external" href="../../../api/bandit/genrl.agents.bandits.multiarmed.html#module-genrl.agents.bandits.multiarmed.thompson">Thompson
Sampling</a>.
But what is different here is that we explicity try to calculate the
uncertainty of a particular action by calculating the standard
deviation(<span class="math notranslate nohighlight">\(\sigma\)</span>) of its posterior. We add this std. dev to
the mean of the posterior, giving us an <em>upper bound</em> of the quality of
that arm. At each timestep we select a greedy action based on this upper
bound we calculated.</p>
<div class="math notranslate nohighlight">
\[a_t = argmax(q_t(a) + \sigma_{q_t})\]</div>
<p>As we try out an action more and more, the standard deviation of the
posterior decreases, corresponding to a decrease in the uncertainty of
that action, which is exactly what we want. If an action has not been
tried that often, it will have a wider posterior, meaning higher chances
of it getting selected based on its upper bound.</p>
<p>Code to use Bayesian method on a Bernoulli Multi-Armed Bandit:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">genrl.bandit</span> <span class="kn">import</span> <span class="n">BayesianUCBMABAgent</span><span class="p">,</span> <span class="n">BernoulliMAB</span><span class="p">,</span> <span class="n">MABTrainer</span>

<span class="n">bandits</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">arms</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mf">1.0</span>

<span class="n">reward_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">bandits</span><span class="p">,</span> <span class="n">arms</span><span class="p">))</span>
<span class="n">bandit</span> <span class="o">=</span> <span class="n">BernoulliMAB</span><span class="p">(</span><span class="n">bandits</span><span class="p">,</span> <span class="n">arms</span><span class="p">,</span> <span class="n">reward_probs</span><span class="p">,</span> <span class="n">context_type</span><span class="o">=</span><span class="s2">&quot;int&quot;</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">BayesianUCBMABAgent</span><span class="p">(</span><span class="n">bandit</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">MABTrainer</span><span class="p">(</span><span class="n">agent</span><span class="p">,</span> <span class="n">bandit</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
</pre></div>
</div>
<p>More details can be found in the docs for
<a class="reference external" href="../../../api/bandit/genrl.core.bandit.html#genrl.core.bandit.bernoulli_mab.BernoulliMAB">BernoulliMAB</a>,
<a class="reference external" href="../../../api/bandit/genrl.agents.bandits.multiarmed.html#module-genrl.agents.bandits.multiarmed.bayesian">BayesianUCBMABAgent</a>
and
<a class="reference external" href="../../../api/common/bandit.html#module-genrl.bandit.trainer">MABTrainer</a>.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="gradients.html" class="btn btn-neutral float-right" title="Gradients" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="thompson_sampling.html" class="btn btn-neutral float-left" title="Thompson Sampling" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Society for Artificial Intelligence and Deep Learning (SAiDL)

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>